{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":617479,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":464252,"modelId":480040},{"sourceId":617482,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":464255,"modelId":480043},{"sourceId":617493,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":464264,"modelId":480053}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nfrom transformers import logging\n\nwarnings.filterwarnings(\"ignore\")\nlogging.set_verbosity_error()\n\nfrom transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline, MarianMTModel, MarianTokenizer\n\nqa_model_name = \"/kaggle/input/roberta-qa-2/pytorch/default/1/roberta-qa-finetuned\"\nqa_tokenizer = AutoTokenizer.from_pretrained(qa_model_name)\nqa_model = AutoModelForQuestionAnswering.from_pretrained(qa_model_name)\nqa_pipeline = pipeline(\"question-answering\", model=qa_model, tokenizer=qa_tokenizer)\n\ntranslation_model_name = \"/kaggle/input/translate/tensorflow2/default/1/translation-model\"  # example English â†’ French\ntranslation_tokenizer = MarianTokenizer.from_pretrained(translation_model_name)\ntranslation_model = MarianMTModel.from_pretrained(translation_model_name)\n\n\n\ndef translate_en_to_fr(text):\n    inputs = translation_tokenizer(text, return_tensors=\"pt\", padding=True)\n    translated = translation_model.generate(**inputs)\n    return translation_tokenizer.decode(translated[0], skip_special_tokens=True)\n\ndef answer_in_french(context, question):\n    # Step 1: English QA\n    qa_input = {\"question\": question, \"context\": context}\n    answer_en = qa_pipeline(qa_input)[\"answer\"]\n    \n    # Step 2: Translate answer to French\n    answer_fr = translate_en_to_fr(answer_en)\n    return answer_fr\n\n\ncontext = \"amey loves eating pizza in afternoon\"\nquestion = \"amey loves what?\"\n\nfrench_answer = answer_in_french(context, question)\nprint(\"Answer in French:\", french_answer)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-23T16:26:51.513782Z","iopub.execute_input":"2025-10-23T16:26:51.514279Z","iopub.status.idle":"2025-10-23T16:26:54.370604Z","shell.execute_reply.started":"2025-10-23T16:26:51.514255Z","shell.execute_reply":"2025-10-23T16:26:54.369639Z"}},"outputs":[{"name":"stdout","text":"Answer in French: Amey adore manger des pizzerias.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}